{"cells":[{"source":"<center><img src=\"educational_quiz_bot.jpg\" width=300></center>\n\n    \nQuizzes are a useful way to practice what you or your students have learned and to keep track of progress. In this project, we'll build a educational quiz bot to help generate quiz questions. Imagine you are a teacher needing to create a pop quiz based on your most recent lecture, or you are a student wanting to quiz yourself on this lecture. This tool will help you automate this task, track which questions have been asked to avoid repetition, and validate the responses.\n\n### The Data:\n\nThis quiz bot allows you to generate quizzes from any educational text. You have been provided with a sample data file from a physics-focused corpus, stored in the `physics_lecture.txt` file.\n\nThe text covers fundamental physics concepts, including speed, velocity, Newton's third law, and more. This content is sourced from ScienceQA (Saikh et al., 2022), a dataset originally designed for Machine Reading Comprehension (MRC) tasks. For this project, the dataset has been filtered to focus specifically on natural science topics related to physics, making it ideal for use with the quiz bot.\n\nSource: `https://huggingface.co/datasets/tasksource/ScienceQA_text_only?row=40`\nSaikh, Tanik et al. “ScienceQA: a novel resource for question answering on scholarly articles.” International Journal on Digital Libraries 23 (2022): 289 - 301.\n\nImage generated with DALL-E (OpenAI)","metadata":{},"id":"b261949f-b6a3-4c0c-b6f7-1e8403f2b659","cell_type":"markdown"},{"source":"# Import OpenAI and supporting libraries\nimport os\nfrom openai import OpenAI\n\ndef read_text_from_file(filename):\n    \"\"\"\n    Reads the first 500 lines of content from a file and returns it as a string.\n    Args: filename (str): The name of the file to read.\n    Returns: str: The content of the file as a string, or an empty string if the file is not found.\n    \"\"\"\n    try:\n        with open(filename, 'r') as file:\n            return ''.join([next(file) for _ in range(500)])\n    except FileNotFoundError:\n        print(f\"Error: {filename} not found.\")\n        return \"\"\n\n# Read content from the file\ncontent = read_text_from_file(\"physics_lecture.txt\")\n\n# Set up the OpenAI client\n#client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n\n# Setting up the recommended model\n#model = \"gpt-4o-mini\"\n\n# Define the model to use\nmodel = \"gemini-1.5-flash\"\n\n# Define the client\nclient = OpenAI(api_key=os.environ[\"GEMINI_API_KEY\"],  base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1740156421613,"lastExecutedByKernel":"b432ea18-76c4-4269-bcdf-d796d459b66b","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import OpenAI and supporting libraries\nimport os\nfrom openai import OpenAI\n\ndef read_text_from_file(filename):\n    \"\"\"\n    Reads the first 500 lines of content from a file and returns it as a string.\n    Args: filename (str): The name of the file to read.\n    Returns: str: The content of the file as a string, or an empty string if the file is not found.\n    \"\"\"\n    try:\n        with open(filename, 'r') as file:\n            return ''.join([next(file) for _ in range(500)])\n    except FileNotFoundError:\n        print(f\"Error: {filename} not found.\")\n        return \"\"\n\n# Read content from the file\ncontent = read_text_from_file(\"physics_lecture.txt\")\n\n# Set up the OpenAI client\n#client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n\n# Setting up the recommended model\n#model = \"gpt-4o-mini\"\n\n# Define the model to use\nmodel = \"gemini-1.5-flash\"\n\n# Define the client\nclient = OpenAI(api_key=os.environ[\"GEMINI_API_KEY\"],  base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")","outputsMetadata":{"0":{"height":616,"type":"stream"}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"id":"aa14cf8e-a933-4a6b-9fed-90b1fd10f152","cell_type":"code","execution_count":9,"outputs":[]},{"source":"# Define the system prompt (describing the assistant's behavior)\nsystem_prompt = \"\"\"\nYou are a teaching assistant that generates multiple-choice questions from a provided educational text.\nYour role is to assist educators by creating quiz questions with one correct answer.\n\"\"\"","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1740156421664,"lastExecutedByKernel":"b432ea18-76c4-4269-bcdf-d796d459b66b","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define the system prompt (describing the assistant's behavior)\nsystem_prompt = \"\"\"\nYou are a teaching assistant that generates multiple-choice questions from a provided educational text.\nYour role is to assist educators by creating quiz questions with one correct answer.\n\"\"\""},"cell_type":"code","id":"8f28a627-5c3d-4101-8a9b-723ecbd6719e","outputs":[],"execution_count":10},{"source":"# Define the user prompt template (input provided by the user)\nuser_prompt = \"\"\"\nGenerate a multiple-choice quiz question from the given text:\n\nFormat:\nQuestion: <Generated Question>\nOptions:\na) <Option 1>\nb) <Option 2>\nc) <Option 3>\nd) <Option 4>\nAnswer: <Correct Option>\n\"\"\"","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1740156421712,"lastExecutedByKernel":"b432ea18-76c4-4269-bcdf-d796d459b66b","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define the user prompt template (input provided by the user)\nuser_prompt = \"\"\"\nGenerate a multiple-choice quiz question from the given text:\n\nFormat:\nQuestion: <Generated Question>\nOptions:\na) <Option 1>\nb) <Option 2>\nc) <Option 3>\nd) <Option 4>\nAnswer: <Correct Option>\n\"\"\""},"cell_type":"code","id":"9307fe8b-79e4-4342-a738-2aa27f2b9aa1","outputs":[],"execution_count":11},{"source":"def generate_quiz_questions(text):\n    \"\"\"\n    Generates a list of multiple-choice quiz questions and answers from the provided text.\n    Args: text (str): The input text from which quiz questions are generated.\n    Returns: list: A list of dictionaries containing quiz questions, options, and correct answers.\n    \"\"\"\n    # List to store generated quiz questions and answers\n    quiz_data_list = []\n\n    for i in range(5):\n        \n        # Get a response from the OpenAI API to generate the quiz questions\n        response = client.chat.completions.create(\n            model=model,\n            messages=[\n                {\"role\": \"system\", \"content\": system_prompt + text},\n                {\"role\": \"user\", \"content\": user_prompt}\n            ],\n            max_tokens=1000\n        )\n\n        # Extract the questions and answers from the response\n        question_and_answer = response.choices[0].message.content\n\n        # Add the generated question and answer to the list\n        quiz_data_list.append(question_and_answer)\n\n    return quiz_data_list","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1740156421764,"lastExecutedByKernel":"b432ea18-76c4-4269-bcdf-d796d459b66b","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def generate_quiz_questions(text):\n    \"\"\"\n    Generates a list of multiple-choice quiz questions and answers from the provided text.\n    Args: text (str): The input text from which quiz questions are generated.\n    Returns: list: A list of dictionaries containing quiz questions, options, and correct answers.\n    \"\"\"\n    # List to store generated quiz questions and answers\n    quiz_data_list = []\n\n    for i in range(5):\n        \n        # Get a response from the OpenAI API to generate the quiz questions\n        response = client.chat.completions.create(\n            model=model,\n            messages=[\n                {\"role\": \"system\", \"content\": system_prompt + text},\n                {\"role\": \"user\", \"content\": user_prompt}\n            ],\n            max_tokens=1000\n        )\n\n        # Extract the questions and answers from the response\n        question_and_answer = response.choices[0].message.content\n\n        # Add the generated question and answer to the list\n        quiz_data_list.append(question_and_answer)\n\n    return quiz_data_list"},"id":"c3192275-df59-4dee-9f42-fd782fc4e600","cell_type":"code","execution_count":12,"outputs":[]},{"source":"# Generate quiz questions from the content provided\nquiz_data = generate_quiz_questions(content)\n\n# View the first question and answer set\nprint(quiz_data[0])","metadata":{"executionCancelledAt":null,"executionTime":7242,"lastExecutedAt":1740156429008,"lastExecutedByKernel":"b432ea18-76c4-4269-bcdf-d796d459b66b","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Generate quiz questions from the content provided\nquiz_data = generate_quiz_questions(content)\n\n# View the first question and answer set\nprint(quiz_data[0])","outputsMetadata":{"0":{"height":248,"type":"stream"}}},"cell_type":"code","id":"25cfadb4-562d-45bd-81bb-dc1052a8176f","outputs":[{"output_type":"stream","name":"stdout","text":"Question:  A 2-kilogram brick and a 1-kilogram brick are both at 70°F.  Which brick has more thermal energy?\n\nOptions:\na) The 1-kilogram brick\nb) The 2-kilogram brick\nc) Both bricks have the same thermal energy\nd) It depends on the material the bricks are made of\n\nAnswer: b) The 2-kilogram brick\n\n"}],"execution_count":13}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}